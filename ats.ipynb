{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccd7b5b-b8b0-47fb-86b3-138d8b597950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126479f6-81ce-4e79-9eab-8a90043efb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c0f667-5fe6-40a8-b1ee-38ab9daec5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31a06ea-be77-4402-85a0-e04e4baffd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mateen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mateen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ccee1d-51bd-4376-837d-5b5d92a2c67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.3.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mateen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.3.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mateen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.3.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = pickle.load(open('model.pkl','rb'))\n",
    "tfidfd = pickle.load(open('tfidf.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8480bbd-1fc6-4337-afc1-397ae13cd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_resume(resume_text):\n",
    "    clean_text = re.sub('http\\S+\\s*',' ',resume_text)\n",
    "    clean_text = re.sub('RT|cc',' ',clean_text)\n",
    "    clean_text = re.sub('#\\S+',' ',clean_text)\n",
    "    clean_text = re.sub('@\\S+',' ',clean_text)\n",
    "    clean_text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}),clean_text~\"\"\"), ' ', clean_text)\n",
    "    clean_text = re.sub('\\s+',' ',clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb193e5-2d68-46d8-914a-d621d08c40d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#web app\n",
    "def main():\n",
    "    st.title(\"Resume Screening App\")\n",
    "    uploaded_file  = st.file_uploader('Upload Resume', type = ['txt','pdf'])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        try:\n",
    "            resume_bytes = uploaded_file.read()\n",
    "            resume_text = resume_bytes.decode('utf-8')\n",
    "        except UnicodeDecoderError:\n",
    "            resume_text = resume_bytes.decode('latin - 1') #if UTF -8 decoding fails, try decoding with latin -1\n",
    "            \n",
    "        cleaned_resume = clean_resume(resume_text)\n",
    "        input_features = tfidfd.tranform([cleaned_resume])\n",
    "        prediction_id = clf.predict(input_features)[0]\n",
    "        st.write(prediction_id)\n",
    "        #mapping category id to category name\n",
    "        category_mapping = {\n",
    "               15 : 'Java Developer',\n",
    "               23 : 'Testing',\n",
    "               8 : 'DevOps Engineer',\n",
    "               20 : 'Python Developer',\n",
    "               24 : 'Web Designing',\n",
    "               12 : 'HR',\n",
    "               13 : 'Hadoop',\n",
    "               3 : 'Blockchain',\n",
    "               10 : 'ETL Developer',\n",
    "               18 : 'Operations Manager',\n",
    "               6 : 'Data Science',\n",
    "               22 : 'Sales',\n",
    "               16 : 'Mechanical Engineer',\n",
    "               1 : 'Arts',\n",
    "               7 : 'Database',\n",
    "               2 : 'Business Analyst',\n",
    "               11 : 'Electrical Engineering',\n",
    "               14 : 'Health and fitness',\n",
    "               19 : 'PMO',\n",
    "               4: 'Business Analyst',\n",
    "               9: 'DotNet Developer',\n",
    "               2: 'Automation Testing',\n",
    "               17: 'Netwrok Security Engineer',\n",
    "               21: 'SAP Developer',\n",
    "               5: 'Civil Engineer',\n",
    "               0: 'Advocate',   \n",
    "        }\n",
    "        category_name = category_mapping.get(prediciton_id,'Unknown')\n",
    "        st.write (\"Predicted Category\", category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9085a28-a73e-41a5-8259-e48285d437cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 17:39:47.041 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Mateen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#python main\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121310c3-8c00-4bf4-9435-a022f92fad92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
